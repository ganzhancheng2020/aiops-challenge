{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237d84a6-dff1-435c-a01a-0b9744aa35df",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T16:52:46.815241Z",
     "iopub.status.busy": "2024-07-04T16:52:46.815008Z",
     "iopub.status.idle": "2024-07-04T16:52:50.677500Z",
     "shell.execute_reply": "2024-07-04T16:52:50.676920Z",
     "shell.execute_reply.started": "2024-07-04T16:52:46.815221Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from llama_index.core.extractors import SummaryExtractor\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.llms.llm import LLM\n",
    "from llama_index.core.vector_stores.types import BasePydanticVectorStore\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import Document, MetadataMode\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from ReadLoad import read_jsonl, write_jsonl\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefc5234-0b32-4aa9-944a-d8c0fad8fe53",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-06-20T07:11:22.799671Z",
     "iopub.status.busy": "2024-06-20T07:11:22.799370Z",
     "iopub.status.idle": "2024-06-20T07:11:22.802197Z",
     "shell.execute_reply": "2024-06-20T07:11:22.801722Z",
     "shell.execute_reply.started": "2024-06-20T07:11:22.799652Z"
    },
    "tags": []
   },
   "source": [
    "### load document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987febb1-dd01-444e-9118-21ef6cea0882",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T16:52:54.301796Z",
     "iopub.status.busy": "2024-07-04T16:52:54.301442Z",
     "iopub.status.idle": "2024-07-04T16:52:59.329692Z",
     "shell.execute_reply": "2024-07-04T16:52:59.329174Z",
     "shell.execute_reply.started": "2024-07-04T16:52:54.301775Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "def read_data(path: str = \"data\") -> list[\"data\"]:\n",
    "    reader = SimpleDirectoryReader(\n",
    "        input_dir=path,\n",
    "        recursive=True,\n",
    "        required_exts=[\n",
    "            \".txt\",\n",
    "        ],\n",
    "    )\n",
    "    return reader.load_data()\n",
    "\n",
    "#data_splite\n",
    "data = read_data(\"./aiops2024-challenge-dataset/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab1b799-7606-4b42-ad8b-05e66fc14fd1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T16:52:59.330835Z",
     "iopub.status.busy": "2024-07-04T16:52:59.330595Z",
     "iopub.status.idle": "2024-07-04T16:52:59.355247Z",
     "shell.execute_reply": "2024-07-04T16:52:59.354663Z",
     "shell.execute_reply.started": "2024-07-04T16:52:59.330818Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20733"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [ d for d in data if len(d.text) > 100]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b0ee3d9-153b-41c7-86ae-083e1ed9c0cf",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef353f-0e25-456a-ae5e-c9db7a96ed5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T07:12:23.219249Z",
     "iopub.status.busy": "2024-06-20T07:12:23.218902Z",
     "iopub.status.idle": "2024-06-20T07:12:23.222321Z",
     "shell.execute_reply": "2024-06-20T07:12:23.221589Z",
     "shell.execute_reply.started": "2024-06-20T07:12:23.219227Z"
    },
    "tags": []
   },
   "source": [
    "### Setup embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f2c59c4-12ef-4e45-81d5-5e968dae6c47",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T16:53:03.240701Z",
     "iopub.status.busy": "2024-07-04T16:53:03.240361Z",
     "iopub.status.idle": "2024-07-04T16:53:06.654969Z",
     "shell.execute_reply": "2024-07-04T16:53:06.654430Z",
     "shell.execute_reply.started": "2024-07-04T16:53:03.240681Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# embeding \n",
    "embeding = HuggingFaceEmbedding(\n",
    "        model_name=\"bge-small-zh-v1.5\",\n",
    "        cache_folder=\"./\",\n",
    "        embed_batch_size=512,\n",
    "    )\n",
    "Settings.embed_model = embeding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21f4ecf-5f38-4e51-8a9d-e3c896e911b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T07:12:58.937180Z",
     "iopub.status.busy": "2024-06-20T07:12:58.936858Z",
     "iopub.status.idle": "2024-06-20T07:12:58.940175Z",
     "shell.execute_reply": "2024-06-20T07:12:58.939378Z",
     "shell.execute_reply.started": "2024-06-20T07:12:58.937160Z"
    },
    "tags": []
   },
   "source": [
    "### Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8426cbf-09ee-448e-be82-603ca9d91299",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T16:53:06.699999Z",
     "iopub.status.busy": "2024-07-04T16:53:06.699617Z",
     "iopub.status.idle": "2024-07-04T16:53:06.839817Z",
     "shell.execute_reply": "2024-07-04T16:53:06.839297Z",
     "shell.execute_reply.started": "2024-07-04T16:53:06.699980Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zhipuLLM import GLM\n",
    "glm =  GLM()\n",
    "Settings.llm = glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5989659-4a07-4611-80da-28b434c4073d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T16:53:09.073219Z",
     "iopub.status.busy": "2024-07-04T16:53:09.072646Z",
     "iopub.status.idle": "2024-07-04T16:53:10.554074Z",
     "shell.execute_reply": "2024-07-04T16:53:10.553601Z",
     "shell.execute_reply.started": "2024-07-04T16:53:09.073193Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.644 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "import json\n",
    "# 打开并读取JSON文件\n",
    "# with open('dictionary.json', 'r', encoding='utf-8') as f:\n",
    "#     dictionary = json.load(f)\n",
    "# dictionary =  {k.lower(): v for k, v in dictionary.items()}\n",
    "\n",
    "jieba.load_userdict(\"words.txt\")\n",
    "def chinese_tokenizer(text: str) -> list[str]:\n",
    "    tokens = jieba.lcut(text)\n",
    "    # TOOD: 短语不可分割\n",
    "    # TODO: remove stopwords\n",
    "    return tokens\n",
    "\n",
    "def expand_abbreviations(sentence):\n",
    "    # 将句子分割成单词列表\n",
    "    words = jieba.lcut(sentence)\n",
    "    \n",
    "    # 遍历单词列表\n",
    "    for i, word in enumerate(words):\n",
    "        # 检查单词是否在字典的键中\n",
    "        word = word.lower()\n",
    "        if word in dictionary:\n",
    "            # 替换缩写为全写\n",
    "            words[i] = f\"{words[i]}({dictionary[word]})\"\n",
    "    \n",
    "    # 将修改后的单词列表重新组合成一个句子\n",
    "    expanded_sentence = ''.join(words)\n",
    "    \n",
    "    return expanded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e18fec-5c4b-4fe5-96f9-9327d332351a",
   "metadata": {},
   "source": [
    "### Metadata exctraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3a6091f-ef5e-48c4-83cd-4efe1c59af83",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T16:57:32.364019Z",
     "iopub.status.busy": "2024-07-04T16:57:32.363687Z",
     "iopub.status.idle": "2024-07-04T16:57:32.461486Z",
     "shell.execute_reply": "2024-07-04T16:57:32.460961Z",
     "shell.execute_reply.started": "2024-07-04T16:57:32.363999Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20733/20733 [00:00<00:00, 226476.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(data):\n",
    "    l = file.metadata['file_path'].split('/')\n",
    "    file.metadata['product_name'] = l[5]\n",
    "    file.metadata['document_name'] = l[6]\n",
    "    file.metadata['Topic'] = file.text.splitlines()[0]\n",
    "    # file.metadata['keywords'] = jieba.analyse.extract_tags(file.text, topK=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9668b8de-cb69-4b0a-b2ff-5fe9ed2e277e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T16:57:35.566908Z",
     "iopub.status.busy": "2024-07-04T16:57:35.566520Z",
     "iopub.status.idle": "2024-07-04T16:58:38.632415Z",
     "shell.execute_reply": "2024-07-04T16:58:38.631829Z",
     "shell.execute_reply.started": "2024-07-04T16:57:35.566885Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import (\n",
    "    HierarchicalNodeParser,\n",
    "    SentenceSplitter,\n",
    ")\n",
    "node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes = [2048,1024,256])\n",
    "nodes = node_parser.get_nodes_from_documents(data)\n",
    "\n",
    "# splitter = SentenceSplitter(chunk_size=1024,chunk_overlap=32)\n",
    "# nodes = splitter.get_nodes_from_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c6cace9-e8e3-4b94-8de8-63870a0ffc34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T16:58:38.633600Z",
     "iopub.status.busy": "2024-07-04T16:58:38.633347Z",
     "iopub.status.idle": "2024-07-04T16:58:38.785048Z",
     "shell.execute_reply": "2024-07-04T16:58:38.784536Z",
     "shell.execute_reply.started": "2024-07-04T16:58:38.633582Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import get_leaf_nodes, get_root_nodes\n",
    "leaf_nodes = get_leaf_nodes(nodes)\n",
    "root_nodes = get_root_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4062ad2e-0a94-4158-bcba-d4701a7f9ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31377/31377 [02:16<00:00, 230.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.schema import IndexNode\n",
    "sub_chunk_sizes = [256, 512]\n",
    "sub_node_parsers = [\n",
    "    SentenceSplitter(chunk_size=c, chunk_overlap=20) for c in sub_chunk_sizes\n",
    "]\n",
    "\n",
    "all_nodes = []\n",
    "for base_node in tqdm(nodes):\n",
    "    for n in sub_node_parsers:\n",
    "        sub_nodes = n.get_nodes_from_documents([base_node])\n",
    "        sub_inodes = [\n",
    "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n",
    "        ]\n",
    "        all_nodes.extend(sub_inodes)\n",
    "\n",
    "    # also add original node to node\n",
    "    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n",
    "    all_nodes.append(original_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90fdcd27-9ea6-43ff-b4e0-0f15dddc32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_dict = {n.node_id: n for n in all_nodes}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86727b5b-bc4b-4834-935f-b78294586727",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-06-20T07:15:31.654302Z",
     "iopub.status.busy": "2024-06-20T07:15:31.653980Z",
     "iopub.status.idle": "2024-06-20T07:15:31.656820Z",
     "shell.execute_reply": "2024-06-20T07:15:31.656358Z",
     "shell.execute_reply.started": "2024-06-20T07:15:31.654283Z"
    },
    "tags": []
   },
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a2a9a83-547d-4407-917e-61aedbc9e24b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T16:58:38.786007Z",
     "iopub.status.busy": "2024-07-04T16:58:38.785732Z",
     "iopub.status.idle": "2024-07-04T17:03:12.060513Z",
     "shell.execute_reply": "2024-07-04T17:03:12.059967Z",
     "shell.execute_reply.started": "2024-07-04T16:58:38.785984Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vector_index = VectorStoreIndex(nodes)\n",
    "# import torch\n",
    "# del my_tensor\n",
    "# torch.cuda.empty_cache()\n",
    "#vector_index = VectorStoreIndex.from_documents(data)\n",
    "#vector_index = VectorStoreIndex(nodes=nodes)\n",
    "#vector_index = VectorStoreIndex(nodes=all_nodes) # Recursive Retriever\n",
    "vector_index = VectorStoreIndex(nodes=leaf_nodes) # AutoMergingRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a674dff-f85c-4644-9dff-ad5ff9edbf60",
   "metadata": {},
   "source": [
    "### Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f645af0e-bc0d-4556-ad0c-0853a742abee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StorageContext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m vector_index\u001b[38;5;241m.\u001b[39mstorage_context\u001b[38;5;241m.\u001b[39mpersist(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./storage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# rebuild storage context\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m storage_context \u001b[38;5;241m=\u001b[39m \u001b[43mStorageContext\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_defaults(persist_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# load index\u001b[39;00m\n\u001b[1;32m      7\u001b[0m index \u001b[38;5;241m=\u001b[39m load_index_from_storage(storage_context, index_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StorageContext' is not defined"
     ]
    }
   ],
   "source": [
    "# save index to disk\n",
    "vector_index.set_index_id(\"vector_index\")\n",
    "vector_index.storage_context.persist(\"./storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459489e-5288-46ef-9434-d03fee8f80e5",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "171d3497-127d-42fb-95f2-105a6e00e185",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T17:06:35.310092Z",
     "iopub.status.busy": "2024-07-04T17:06:35.309762Z",
     "iopub.status.idle": "2024-07-04T17:07:36.583284Z",
     "shell.execute_reply": "2024-07-04T17:07:36.582767Z",
     "shell.execute_reply.started": "2024-07-04T17:06:35.310072Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "\n",
    "# insert nodes into docstore\n",
    "docstore.add_documents(nodes)\n",
    "\n",
    "# define storage context (will include vector store by default too)\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)\n",
    "\n",
    "#vector_retriever = vector_index.as_retriever(similarity_top_k=10,similarity_threshold=0.6)\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=10)\n",
    "bm25_retriever = BM25Retriever.from_defaults(nodes=leaf_nodes, similarity_top_k=10,tokenizer=chinese_tokenizer)\n",
    "# recursive_retriever = RecursiveRetriever(\n",
    "#     \"vector\",\n",
    "#     retriever_dict={\"vector\": vector_retriever},\n",
    "#     node_dict=all_nodes_dict,\n",
    "#     similarity_threshold=0.5,\n",
    "#     #verbose=True,\n",
    "# )\n",
    "AutoMerging_retriever = AutoMergingRetriever(vector_retriever,storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "892911ee-356d-45a1-b0e8-f4dd920e4f70",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T17:15:01.260018Z",
     "iopub.status.busy": "2024-07-04T17:15:01.259688Z",
     "iopub.status.idle": "2024-07-04T17:15:02.859826Z",
     "shell.execute_reply": "2024-07-04T17:15:02.859377Z",
     "shell.execute_reply.started": "2024-07-04T17:15:01.259998Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "发布虚机时最多可以为虚机分配几块网卡？\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 9e4cbee1-4fbe-4101-bd93-af57b50b84a3<br>**Similarity:** 0.669169815873576<br>**Text:** 图5 网络配置（虚机）\n",
       "\n",
       "说明：\n",
       "\n",
       "虚机场景注意事项：\n",
       "\n",
       "       * 运维网络”VIP填写运维网络浮动IP，地址池填写预置虚机所有节点的真实运维IP地址（固化到虚机网卡文件的net_iap...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 2a55564c-79d1-4696-82a0-0909495c18ce<br>**Similarity:** 0.6642504539058531<br>**Text:** 表7 网络平面规划数据（非SDN组网）VM| 网络平面  \n",
       "---|---  \n",
       "OMU| ZTE_EMS_NET  \n",
       "ZTE_AMF_x_MGT_INT_NET  \n",
       "ZTE_AMF_x_SERV...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 305006b1-f4ae-413b-8f0c-305f4d3cf2d8<br>**Similarity:** 0.6562133250682154<br>**Text:** C100013001 虚机网卡数目\n",
       "\n",
       "  * C100013002 虚机最大网卡数目\n",
       "\n",
       "  * C100013003 虚机最小网卡数目\n",
       "\n",
       "  * C100013004 虚机自启动以来虚机运行时长...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 6d4616b1-b808-470b-ab35-fa5ee52c72a6<br>**Similarity:** 0.6542932158055011<br>**Text:** 表2 IPU虚机网卡配置参数说明 参数名称 | 参数含义  \n",
       "---|---  \n",
       "关联网络名称 | 此参数表示IPU虚机关联的网络平面名称，IPU需要关联的网络平面如下。\n",
       "\n",
       "  * ZTE_AM...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 0eaa1002-76d8-4f11-baf6-52f3eefc8cf8<br>**Similarity:** 0.6530379905498399<br>**Text:** IMU虚机配置\n",
       "\n",
       "概述\n",
       "\n",
       "在部署了安全网关功能的情况下，才需要配置此种类型的虚机。\n",
       "\n",
       "本节只介绍与IMU虚机相关的主要参数，其它的没有说明的参数参见“OMU虚机配置”。\n",
       "\n",
       "虚机网卡配置\n",
       "\n",
       "各种类...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 7fc490a8-0864-4dba-bf23-20a4d59cb247<br>**Similarity:** 0.6490676265024378<br>**Text:** IAU虚机配置\n",
       "\n",
       "概述\n",
       "\n",
       "在部署了安全网关功能的情况下，才需要配置此种类型的虚机。\n",
       "\n",
       "本节只介绍与IAU虚机相关的主要参数，其它的没有说明的参数参见“OMU虚机配置”。\n",
       "\n",
       "虚机网卡配置\n",
       "\n",
       "各种类...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 7972571e-c0b8-43d2-83ee-420ec41f1356<br>**Similarity:** 0.6458370164628259<br>**Text:** 登录到虚机节点，执行ifconfig -a，可查看虚机网卡的mac地址，如图26所示。\n",
       "\n",
       "图26 查看虚机网卡的mac地址\n",
       "\n",
       "通过mac地址就可以确定虚机网卡挂载的网络信息。\n",
       "\n",
       "  2. 固化n...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b40d10f8-f9ec-467c-9839-e8c7640fd2bc<br>**Similarity:** 0.644548537394399<br>**Text:** 图1 CDU虚机网卡配置\n",
       "\n",
       "CDU虚机网卡配置主要参数说明参见表2。\n",
       "\n",
       "表2 CDU虚机网卡配置参数说明 参数名称 | 参数含义  \n",
       "---|---  \n",
       "关联网络名称 | 此参数表示CDU虚机关...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** c92d22ea-6580-467d-acd0-8b2bd5c15c85<br>**Similarity:** 0.6431587099688861<br>**Text:** 表8 OMU虚机网卡配置参数说明参数名称| 参数含义  \n",
       "---|---  \n",
       "关联网络名称| 该参数的取值有两种情况：\n",
       "\n",
       "  * 设置为通用页面中，配置的网络平面。<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 2ca5b08b-3b2b-4f43-b37c-62bf718db437<br>**Similarity:** 0.6416023963862393<br>**Text:** * 在计算资源充足的情况下，虚拟机必须部署在不同主机（计算节点）上。\n",
       "    * 在计算资源不足情况下，尽可能将这些虚拟机部署在不同的主机（计算节点）上，避免剩余的虚机无法部署。\n",
       "\n",
       "  \n",
       "  \n",
       "...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "query = \"发布虚机时最多可以为虚机分配几块网卡？\"\n",
    "#test_nodes = bm25_retriever.retrieve(query)\n",
    "#test_nodes = vector_retriever.retrieve(query)\n",
    "#test_nodes = hybrid_retriever.retrieve(query)\n",
    "#test_nodes = vector_retriever.retrieve(query)\n",
    "#test_nodes = recursive_retriever.retrieve(query)\n",
    "test_nodes = AutoMerging_retriever.retrieve(query)\n",
    "print(query)\n",
    "\n",
    "for node in test_nodes:\n",
    "    display_source_node(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f06bc461-0580-434f-8a38-296762d64f21",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T17:08:10.747536Z",
     "iopub.status.busy": "2024-07-04T17:08:10.747194Z",
     "iopub.status.idle": "2024-07-04T17:08:10.752518Z",
     "shell.execute_reply": "2024-07-04T17:08:10.751841Z",
     "shell.execute_reply.started": "2024-07-04T17:08:10.747516Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "\n",
    "class HybridRetriever(BaseRetriever):\n",
    "    def __init__(self, vector_retriever, bm25_retriever):\n",
    "        self.vector_retriever = vector_retriever #vector_retriever\n",
    "        self.bm25_retriever = bm25_retriever\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query, **kwargs):\n",
    "        bm25_nodes = self.bm25_retriever.retrieve(query, **kwargs)\n",
    "        vector_nodes = self.vector_retriever.retrieve(query, **kwargs)\n",
    "\n",
    "        # combine the two lists of nodes\n",
    "        all_nodes = []\n",
    "        node_ids = set()\n",
    "        for n in bm25_nodes + vector_nodes:\n",
    "            if n.node.node_id not in node_ids:\n",
    "                all_nodes.append(n)\n",
    "                node_ids.add(n.node.node_id)\n",
    "        return all_nodes\n",
    "        \n",
    "#vector_index.as_retriever(similarity_top_k=10)\n",
    "hybrid_retriever = HybridRetriever(AutoMerging_retriever, bm25_retriever)\n",
    "# QueryFusionretriever = QueryFusionRetriever(\n",
    "#     [vector_retriever, bm25_retriever],\n",
    "#     similarity_top_k=2,\n",
    "#     num_queries=4,  # set this to 1 to disable query generation\n",
    "#     mode=\"reciprocal_rerank\",\n",
    "#     use_async=True,\n",
    "#     verbose=True,\n",
    "#     # query_gen_prompt=\"...\",  # we could override the query generation prompt here\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a6375-809b-4ccb-a825-3277bfa885f2",
   "metadata": {},
   "source": [
    "### ReRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee65552d-745d-4607-8fa6-4e86b6643fb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:10:33.015803Z",
     "iopub.status.busy": "2024-07-04T17:10:33.015463Z",
     "iopub.status.idle": "2024-07-04T17:10:34.834470Z",
     "shell.execute_reply": "2024-07-04T17:10:34.833875Z",
     "shell.execute_reply.started": "2024-07-04T17:10:33.015784Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "reranker = SentenceTransformerRerank(top_n=5, model=\"bge-reranker-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69457b24-2d05-4437-bed2-f19dcbe09b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:10:35.819920Z",
     "iopub.status.busy": "2024-07-04T17:10:35.819571Z",
     "iopub.status.idle": "2024-07-04T17:10:35.823251Z",
     "shell.execute_reply": "2024-07-04T17:10:35.822737Z",
     "shell.execute_reply.started": "2024-07-04T17:10:35.819899Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "def rerank_nodes(retriever,reranker,query):\n",
    "\n",
    "    retrieved_nodes = retriever.retrieve(query)\n",
    "    reranked_nodes = reranker.postprocess_nodes(\n",
    "        retrieved_nodes,\n",
    "        query_bundle=QueryBundle(query),\n",
    "    )\n",
    "    return reranked_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5651ed-da50-4530-86db-c58df91f0247",
   "metadata": {},
   "source": [
    "### Setup prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "831c076a-8807-4898-9b4d-1e6c9a985461",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T17:10:40.338911Z",
     "iopub.status.busy": "2024-07-04T17:10:40.338298Z",
     "iopub.status.idle": "2024-07-04T17:10:40.343219Z",
     "shell.execute_reply": "2024-07-04T17:10:40.342636Z",
     "shell.execute_reply.started": "2024-07-04T17:10:40.338890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "new_text_qa_template_str = (\n",
    "    \"\"\"\\\n",
    "    上下文信息如下：\n",
    "    ----------\n",
    "    {context_str}\n",
    "    ----------\n",
    "    根据上下文信息而非先验知识，构建一个经过严谨思考且内容详实的答案，来回答问题。\n",
    "    充分运用上下文信息来支撑你的答案，并确保回答符合人类的偏好以及遵循指示的原则。\n",
    "    如果上下文信息没有相关知识，可以回答不确定，不要复述上下文信息。\n",
    "    \n",
    "    问题：{query_str}\n",
    "    回答：\\\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "text_qa_template_str = (\n",
    "    \"你是一名中兴通讯网络运维专家\\n\"\n",
    "    \"以下是上下文信息：\\n\"\n",
    "    \"---------------------\\n{context_str}\\n---------------------\\n\"\n",
    "    \"运用上下文信息并结合你自己的知识，回答以下问题。\\n\"\n",
    "    \"如果上下文信息没有帮助，你也可以凭自己的知识来回答问题。\\n\"\n",
    "    \"请以专业得风格回答问题\\n\"\n",
    "    \"问题：{query_str}\\n\"\n",
    "    \"回答：\"\n",
    ")\n",
    "\n",
    "text_qa_template = PromptTemplate(new_text_qa_template_str)\n",
    "\n",
    "refine_template_str = (\n",
    "    \"\"\"\\\n",
    "    原始问题如下：\n",
    "    ----------\n",
    "    {query_str}\n",
    "    ----------\n",
    "    我们已经给出一个现有的答案：\n",
    "    ----------\n",
    "    {existing_answer}\n",
    "    ----------\n",
    "    现在，我们有机会根据以下附加信息来优化这个现有答案（仅在必要时进行）。\n",
    "    ----------\n",
    "    {context_msg}\n",
    "    ----------\n",
    "    考虑到新提供的信息，请对原始答案进行改进，以更准确地回答提问。如果新增的信息没有帮助，则直接返回原始答案。\n",
    "    优化后的答案：\\\n",
    "    \"\"\"\n",
    ")\n",
    "refine_template = PromptTemplate(refine_template_str)\n",
    "\n",
    "d ={\"rcp\": \"Resource Control Platform资源控制平台\",\n",
    "    \"umac\": \"unified Mobile Access Controller统一的移动性接入控制器\",\n",
    "    \"emsplus\": \"Element Management System网元管理系统\",\n",
    "    \"director\": \"TECS Director ICT融合的电信级云管理平台\"}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d84f064-b585-48f0-a823-ca96f85a19aa",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6deddee-7a0f-4d30-896d-63e47e931667",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T17:47:15.822392Z",
     "iopub.status.busy": "2024-07-04T17:47:15.822028Z",
     "iopub.status.idle": "2024-07-04T17:47:15.826213Z",
     "shell.execute_reply": "2024-07-04T17:47:15.825595Z",
     "shell.execute_reply.started": "2024-07-04T17:47:15.822369Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.vector_stores import ExactMatchFilter, MetadataFilters,MetadataFilter\n",
    "\n",
    "def hybrid_query2(current_keyword):\n",
    "    query_engine = RetrieverQueryEngine.from_args(\n",
    "        retriever = AutoMerging_retriever, \n",
    "        llm=glm,\n",
    "        text_qa_template=text_qa_template,\n",
    "        refine_template=refine_template,\n",
    "        response_mode=\"compact\",\n",
    "        filters = MetadataFilters(\n",
    "            filters=[ExactMatchFilter(key=\"product_name\", value=current_keyword)]\n",
    "        ),\n",
    "        node_postprocessors=[reranker],\n",
    "        )\n",
    "    return query_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b963791d-8b41-4e5b-9519-df7e3ea3746c",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cd24194-d3bb-4b79-b3bc-de5db19d0ab6",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T17:47:19.034101Z",
     "iopub.status.busy": "2024-07-04T17:47:19.033786Z",
     "iopub.status.idle": "2024-07-04T17:47:26.450975Z",
     "shell.execute_reply": "2024-07-04T17:47:26.450459Z",
     "shell.execute_reply.started": "2024-07-04T17:47:19.034080Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install deepeval\n",
    "# # text\n",
    "question = read_jsonl('./aiops2024-challenge-dataset/question.jsonl')\n",
    "#query_engine = perform_query(vector_index,question[3]['document'])\n",
    "query = question[10]['query']\n",
    "current_keyword = question[10]['document']\n",
    "query_engine = hybrid_query2(current_keyword)\n",
    "response = query_engine.query(query)\n",
    "\n",
    "# print(response.response)\n",
    "# print(\"========================================\")\n",
    "# for source in response.source_nodes:\n",
    "#     print(source.text)\n",
    "#     print(\"========================================\")\n",
    "# def display_prompt_dict(prompts_dict):\n",
    "#     for k, p in prompts_dict.items():\n",
    "#         text_md = f\"**Prompt Key**: {k}\" f\"**Text:** \"\n",
    "#         display(Markdown(text_md))\n",
    "#         print(p.get_template())\n",
    "#         display(Markdown(\"\"))\n",
    "\n",
    "# prompts_dict = query_engine.get_prompts()\n",
    "# display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a61b618-aee1-4035-8e55-4fd7967cc04d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:26:31.421980Z",
     "iopub.status.busy": "2024-07-04T17:26:31.421552Z",
     "iopub.status.idle": "2024-07-04T17:26:31.426787Z",
     "shell.execute_reply": "2024-07-04T17:26:31.426080Z",
     "shell.execute_reply.started": "2024-07-04T17:26:31.421948Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'director'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f78daea0-e29c-4f57-9fff-4f4ec6aa47ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T17:47:30.449593Z",
     "iopub.status.busy": "2024-07-04T17:47:30.449234Z",
     "iopub.status.idle": "2024-07-04T17:47:30.454671Z",
     "shell.execute_reply": "2024-07-04T17:47:30.454119Z",
     "shell.execute_reply.started": "2024-07-04T17:47:30.449566Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "发布虚机时最多可以为虚机分配几块网卡？ director\n",
      "根据提供的上下文信息，关于虚机网卡的分配，我们在“性能计数器参考”文档中找到了相关的信息。具体来说，性能计数器C100013002提到了“虚机最大网卡数目”。然而，文档中并没有给出具体的数字，只是定义了这一性能计数器的用途。\n",
      "\n",
      "因此，基于上下文信息，我无法给出一个具体的数值来回答“发布虚机时最多可以为虚机分配几块网卡”的问题。实际能够分配的最大网卡数目可能取决于具体的系统配置、虚机类型以及所使用的管理软件等因素。\n",
      "\n",
      "如果需要得到这一具体数值，建议查阅具体的系统配置文档或相关的管理软件手册。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'305006b1-f4ae-413b-8f0c-305f4d3cf2d8': {'file_path': '/mnt/workspace/aiops2024-challenge-dataset/data/director/性能计数器参考/1626748224563.txt',\n",
       "  'file_name': '1626748224563.txt',\n",
       "  'file_type': 'text/plain',\n",
       "  'file_size': 6067,\n",
       "  'creation_date': '2024-07-04',\n",
       "  'last_modified_date': '2024-03-12',\n",
       "  'product_name': 'director',\n",
       "  'document_name': '性能计数器参考',\n",
       "  'Topic': '虚机'},\n",
       " '2a55564c-79d1-4696-82a0-0909495c18ce': {'file_path': '/mnt/workspace/aiops2024-challenge-dataset/data/umac/软件安装（MANO）/23-OMU虚机配置(AMF).txt',\n",
       "  'file_name': '23-OMU虚机配置(AMF).txt',\n",
       "  'file_type': 'text/plain',\n",
       "  'file_size': 27307,\n",
       "  'creation_date': '2024-07-04',\n",
       "  'last_modified_date': '2024-05-11',\n",
       "  'product_name': 'umac',\n",
       "  'document_name': '软件安装（MANO）',\n",
       "  'Topic': 'OMU虚机配置'},\n",
       " '2ca5b08b-3b2b-4f43-b37c-62bf718db437': {'file_path': '/mnt/workspace/aiops2024-challenge-dataset/data/umac/软件安装（MANO）/30-IPU虚机配置(AMF).txt',\n",
       "  'file_name': '30-IPU虚机配置(AMF).txt',\n",
       "  'file_type': 'text/plain',\n",
       "  'file_size': 2776,\n",
       "  'creation_date': '2024-07-04',\n",
       "  'last_modified_date': '2024-05-11',\n",
       "  'product_name': 'umac',\n",
       "  'document_name': '软件安装（MANO）',\n",
       "  'Topic': 'IPU虚机配置'},\n",
       " 'b40d10f8-f9ec-467c-9839-e8c7640fd2bc': {'file_path': '/mnt/workspace/aiops2024-challenge-dataset/data/umac/软件安装（MANO）/29-CDU虚机配置(AMF).txt',\n",
       "  'file_name': '29-CDU虚机配置(AMF).txt',\n",
       "  'file_type': 'text/plain',\n",
       "  'file_size': 2279,\n",
       "  'creation_date': '2024-07-04',\n",
       "  'last_modified_date': '2024-05-11',\n",
       "  'product_name': 'umac',\n",
       "  'document_name': '软件安装（MANO）',\n",
       "  'Topic': 'CDU虚机配置'},\n",
       " 'c92d22ea-6580-467d-acd0-8b2bd5c15c85': {'file_path': '/mnt/workspace/aiops2024-challenge-dataset/data/umac/软件安装（MANO）/23-OMU虚机配置(AMF).txt',\n",
       "  'file_name': '23-OMU虚机配置(AMF).txt',\n",
       "  'file_type': 'text/plain',\n",
       "  'file_size': 27307,\n",
       "  'creation_date': '2024-07-04',\n",
       "  'last_modified_date': '2024-05-11',\n",
       "  'product_name': 'umac',\n",
       "  'document_name': '软件安装（MANO）',\n",
       "  'Topic': 'OMU虚机配置'}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(query,current_keyword)\n",
    "print(response.response)\n",
    "response.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8289689-a850-4d5d-8369-8a99bcbf2af2",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "edabddd9-fdbc-4acb-ac65-349e8e98f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    AnswerRelevancyEvaluator,\n",
    "    ContextRelevancyEvaluator\n",
    ")\n",
    "def context_evaluator(query,response):\n",
    "    evaluator = ContextRelevancyEvaluator(llm=glm)\n",
    "    try:\n",
    "        eval_result = evaluator.evaluate_response(query=query, response=response)\n",
    "        return {\n",
    "                \"Query\": str(query),\n",
    "                \"Response\": response.response,\n",
    "                \"Context\": '\\n==========================\\n'.join(eval_result.contexts),\n",
    "                \"Score\": eval_result.score,\n",
    "                \"Evaluation Result\": eval_result.passing,\n",
    "                \"Reasoning\": eval_result.feedback\n",
    "                #\"eval_result\":eval_result\n",
    "            }\n",
    "    except Exception as e:  # Add exception handling for clarity and control\n",
    "        print(f\"An error occurred during evaluation: {e}\")\n",
    "        context_l = [node.text for node in response.source_nodes]\n",
    "    return {\n",
    "        \"Query\": str(query),\n",
    "        \"Response\": response.response,\n",
    "        \"Context\": '\\n==========================\\n'.join(context_l),\n",
    "        \"Score\": \"\",\n",
    "        \"Evaluation Result\": \"\",\n",
    "        \"Reasoning\": \"\"\n",
    "        #\"eval_result\":eval_result\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cdbaeb-f587-4991-84c3-88ee90047e20",
   "metadata": {},
   "source": [
    "### Display prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d356d-4ffb-49f5-bc9b-65362082868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}\" f\"**Text:** \"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"\"))\n",
    "# prompts_dict = query_engine.get_prompts()\n",
    "# display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc683ca7-f7e9-46e3-82bd-645a00bcb2bd",
   "metadata": {},
   "source": [
    "### Query_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1f0a7c9-d973-461a-a51f-434ca0d7ef8f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T17:48:47.113732Z",
     "iopub.status.busy": "2024-07-04T17:48:47.113406Z",
     "iopub.status.idle": "2024-07-04T17:54:44.318252Z",
     "shell.execute_reply": "2024-07-04T17:54:44.317610Z",
     "shell.execute_reply.started": "2024-07-04T17:48:47.113711Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [05:57<00:00,  3.47s/it]\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "#读取问题\n",
    "questions = read_jsonl('./aiops2024-challenge-dataset/question.jsonl')\n",
    "\n",
    "def process_question(q):\n",
    "    #query_engine = perform_query(vector_index,q['document'])\n",
    "    query_engine = hybrid_query(q['document'])\n",
    "    #缩略短语换全写\n",
    "    #query_content = expand_abbreviations(q['query'])\n",
    "    return {\n",
    "        \"id\": q['id'],\n",
    "        \"query\": q['query'],\n",
    "        \"answer\": query_engine.query(q['query'])\n",
    "    }\n",
    "\n",
    "# 并行批量处理\n",
    "def batch_process_questions(questions, max_workers=5):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(process_question, q) for q in questions]\n",
    "        results = [future.result() for future in tqdm(concurrent.futures.as_completed(futures), total=len(questions))]\n",
    "    return results\n",
    "\n",
    "results = batch_process_questions(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006c0f1-b8a0-492d-8917-1840b74dfb1b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "699d6584-6afa-400d-a5f2-bc676b867b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 44/103 [01:39<02:20,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during evaluation: could not convert string to float: '3.0.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 64/103 [02:20<01:17,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during evaluation: could not convert string to float: '4.0.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 79/103 [02:53<01:11,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during evaluation: could not convert string to float: '4.0.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 94/103 [03:25<00:25,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during evaluation: could not convert string to float: '3.0.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [03:53<00:00,  2.27s/it]\n"
     ]
    }
   ],
   "source": [
    "#并行批量处理\n",
    "def batch_process_evaluation(results, max_workers=5):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(context_evaluator, result[\"query\"],result[\"answer\"]) for result in results]\n",
    "        results = [future.result() for future in tqdm(concurrent.futures.as_completed(futures), total=len(results))]\n",
    "    return results\n",
    "\n",
    "eval_results = batch_process_evaluation(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d34543bb-d6a3-4a65-87dd-04d93f13b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(eval_results)\n",
    "df.to_excel(\"1719549918569_0.66.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a387486-6d2d-445f-bee1-42914569093d",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "788784da-37c8-41f5-a6f2-bfac8098caa4",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-07-04T17:54:57.081160Z",
     "iopub.status.busy": "2024-07-04T17:54:57.080748Z",
     "iopub.status.idle": "2024-07-04T17:54:57.289281Z",
     "shell.execute_reply": "2024-07-04T17:54:57.288710Z",
     "shell.execute_reply.started": "2024-07-04T17:54:57.081134Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 383330.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Error 429] Too many requests (wait 587 seconds)\n",
      "提交失败\n"
     ]
    }
   ],
   "source": [
    "final_result = [\n",
    "    {\n",
    "        \"id\": q['id'],\n",
    "        \"query\": q['query'],\n",
    "        \"answer\": q['answer'].response\n",
    "    } for q in tqdm(results)\n",
    "]\n",
    "from submit import submit\n",
    "submission_id = submit(final_result,\n",
    "    judge_server = \"http://judge.aiops-challenge.com\",\n",
    "    contest = \"1780211530478944282\",\n",
    "    ticket = \"1799659042575011879\")\n",
    "if submission_id:\n",
    "    print(\"提交成功！提交 ID: \", submission_id)\n",
    "    print(\"查阅成绩：python submit.py -c 1780211530478944282 -k 1799659042575011879 -i\", submission_id[0])\n",
    "    write_jsonl(final_result, submission_id[0])\n",
    "else:\n",
    "    print(\"提交失败\")\n",
    "    \n",
    "# 1718515109355\n",
    "# 1718542978458\n",
    "# 1718515109355\n",
    "# 1718813723742 metadata vector query 0.59\n",
    "# 1718874184956 中文提示词 0.66\n",
    "# 1718875566919 批量处理\n",
    "# 1718876357723 修改了模型参数 温度为0.1\n",
    "# 1718876982203\n",
    "# 1718881451217\n",
    "# 1718882867809\n",
    "# 1718895050114\n",
    "# 1718898534468\n",
    "# 1718983016865\n",
    "# 1718983745050\n",
    "# 1719145584515\n",
    "# 1719241616258\n",
    "# python submit.py -c 1780211530478944282 -k 1799659042575011879 -i 1719042989786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4092db-add9-4be4-830b-f1620930e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50715e64-b35f-4588-ae65-dee811fdace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
    "\n",
    "# create llm\n",
    "llm = glm\n",
    "\n",
    "# define evaluator\n",
    "evaluator = FaithfulnessEvaluator(llm=llm)\n",
    "\n",
    "# query index\n",
    "question = questions[5]\n",
    "query_engine = perform_query(vector_index,question['document'])\n",
    "response = query_engine.query(\n",
    "    question['query']\n",
    ")\n",
    "eval_result = evaluator.evaluate_response(response=response)\n",
    "print(str(eval_result.passing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876bd9b-59e8-492d-985c-b2aa22942a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95bb04-3655-4bf1-86db-d3612d2f1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone https://www.modelscope.cn/Xorbits/bge-small-zh-v1.5.git\n",
    "# git clone https://www.aiops.cn/gitlab/aiops-challenge/aiops-2024-submit.git\n",
    "# git clone https://www.modelscope.cn/datasets/issaccv/aiops2024-challenge-dataset.git\n",
    "# git clone https://www.modelscope.cn/Xorbits/bge-reranker-base.git\n",
    "# pip install -r requirements.txt\n",
    "# unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889f3e1-5ee1-48e6-ad8a-7879ee7ec488",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(results[1]['query']+\"\\n\",results[1]['answer'])\n",
    "# results[0]['answer'].metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
